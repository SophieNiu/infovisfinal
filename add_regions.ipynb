{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add regions to the congress dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAuthor: Yixian Zhou, ...\\nDate: Dec. 6\\nDescription: \\nAdd regions to the DataFrame of Congress_YCOM_2019_Data.csv\\nAlso some basic exploration\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Author: Yixian Zhou, ...\n",
    "Date: Dec. 6\n",
    "Description: \n",
    "Add regions to the DataFrame of Congress_YCOM_2019_Data.csv\n",
    "Also some basic exploration\n",
    "References: # source: https://www.nationalgeographic.org/maps/united-states-regions/\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import csv\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_modify = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_with_format(l, num_ea_line = 5):\n",
    "    l = list(l)\n",
    "    for i in range(len(l) // num_ea_line):\n",
    "        start = i * num_ea_line\n",
    "        print(\", \".join(l[start:start + num_ea_line]))\n",
    "    if len(l) % num_ea_line != 0: ## there are some left\n",
    "        print(\", \".join(l[i * num_ea_line:]))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## including DC\n",
    "with open(\"state_abbr2full.json\", \"r\") as json_file:\n",
    "    abbr2full = json.load(json_file) \n",
    "\n",
    "with open(\"state_full2abbr.json\", \"r\") as json_file:\n",
    "    full2abbr = json.load(json_file)\n",
    "\n",
    "with open(\"region_states.json\", \"r\") as file:\n",
    "    region_state = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_modify:\n",
    "    ## modify the original dictionary because of debugging or change in reference\n",
    "    state2region = {}\n",
    "    for region, states in region_state.items():\n",
    "        for this_state in states:\n",
    "            state2region[this_state] = region\n",
    "\n",
    "\n",
    "    with open(\"state2region.json\", \"w\") as file:\n",
    "        json.dump(state2region, file, indent=2)\n",
    "else:\n",
    "    ## we usually run this block\n",
    "    with open(\"state2region.json\", \"r\") as file:\n",
    "        state2region = json.load(file)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress_df = pd.read_csv(\"./dataset/Congress_YCOM_2019_Data.csv\")\n",
    "climate_2016 = pd.read_csv(\"./dataset/climate_dataset_cleaned_v1.0.csv\")\n",
    "# climate_2019 = pd.read_excel(\"./dataset/YCOM_2019_Data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df = pd.read_csv(\"./dataset/districteventList.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df_clean = event_df[event_df['state'].isin(list(state2region.keys()))].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xf1 in position 3612: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-30c9560a5812>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1845\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;31m# keep undecoded input until the next call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xf1 in position 3612: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "ycom_data = []\n",
    "with open(\"./dataset/YCOM_2019_Data.csv\", \"r\") as csv_file:\n",
    "    reader = csv.reader(csv_file)\n",
    "    cols = reader.__next__()\n",
    "    i = 0\n",
    "    for row in reader:\n",
    "        if i == 1845:\n",
    "            print(row)\n",
    "#         ycom_data.append(row)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the columns they have in common as well as those uniuqe ones\n",
    "common_cols = []\n",
    "cong_only_cols = []\n",
    "clim_only_cols = list(climate_2016.columns)\n",
    "for col in congress_df.columns:\n",
    "    if col in climate_2016.columns:\n",
    "        common_cols.append(col)\n",
    "        clim_only_cols.remove(col)\n",
    "    else:\n",
    "        cong_only_cols.append(col)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_with_format(cong_only_cols)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print_with_format(cong_only_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress_df['state_abbr'] = congress_df['state_label'].apply(lambda x: full2abbr[x])\n",
    "congress_df['region'] = congress_df['state_abbr'].apply(lambda x: state2region[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df_clean['region'] = event_df_clean['state'].apply(lambda x: state2region[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AK', 'AL', 'AR', 'AZ', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA',\n",
       "       'HI', 'IA', 'ID', 'IL', 'IN', 'KS', 'KY', 'LA', 'MA', 'MD', 'ME',\n",
       "       'MI', 'MN', 'MO', 'MS', 'MT', 'NC', 'ND', 'NE', 'NH', 'NJ', 'NM',\n",
       "       'NV', 'NY', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX',\n",
       "       'UT', 'VA', 'VT', 'WA', 'WI', 'WV', 'WY'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_df_clean['state'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>state</th>\n",
       "      <th>STFIPS</th>\n",
       "      <th>districtId</th>\n",
       "      <th>event</th>\n",
       "      <th>vtec</th>\n",
       "      <th>published</th>\n",
       "      <th>updated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>419347</th>\n",
       "      <td>419348</td>\n",
       "      <td>PR</td>\n",
       "      <td>72</td>\n",
       "      <td>7200</td>\n",
       "      <td>Coastal Flood</td>\n",
       "      <td>CF</td>\n",
       "      <td>2019-01-23 23:56:00</td>\n",
       "      <td>2019-01-23 23:56:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419348</th>\n",
       "      <td>419349</td>\n",
       "      <td>PR</td>\n",
       "      <td>72</td>\n",
       "      <td>7200</td>\n",
       "      <td>Coastal Flood</td>\n",
       "      <td>CF</td>\n",
       "      <td>2019-01-24 00:42:00</td>\n",
       "      <td>2019-01-24 00:42:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419349</th>\n",
       "      <td>419350</td>\n",
       "      <td>PR</td>\n",
       "      <td>72</td>\n",
       "      <td>7200</td>\n",
       "      <td>Coastal Flood</td>\n",
       "      <td>CF</td>\n",
       "      <td>2019-01-24 05:21:00</td>\n",
       "      <td>2019-01-24 05:21:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419350</th>\n",
       "      <td>419351</td>\n",
       "      <td>PR</td>\n",
       "      <td>72</td>\n",
       "      <td>7200</td>\n",
       "      <td>Coastal Flood</td>\n",
       "      <td>CF</td>\n",
       "      <td>2019-01-24 11:39:00</td>\n",
       "      <td>2019-01-24 11:39:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419351</th>\n",
       "      <td>419352</td>\n",
       "      <td>PR</td>\n",
       "      <td>72</td>\n",
       "      <td>7200</td>\n",
       "      <td>Coastal Flood</td>\n",
       "      <td>CF</td>\n",
       "      <td>2019-08-27 18:54:00</td>\n",
       "      <td>2019-08-27 18:54:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420624</th>\n",
       "      <td>420625</td>\n",
       "      <td>PR</td>\n",
       "      <td>72</td>\n",
       "      <td>7200</td>\n",
       "      <td>Wind Advisory</td>\n",
       "      <td>WI</td>\n",
       "      <td>2018-12-29 11:39:00</td>\n",
       "      <td>2018-12-29 11:39:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420625</th>\n",
       "      <td>420626</td>\n",
       "      <td>PR</td>\n",
       "      <td>72</td>\n",
       "      <td>7200</td>\n",
       "      <td>Wind Advisory</td>\n",
       "      <td>WI</td>\n",
       "      <td>2018-12-29 13:35:00</td>\n",
       "      <td>2018-12-29 13:35:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420626</th>\n",
       "      <td>420627</td>\n",
       "      <td>PR</td>\n",
       "      <td>72</td>\n",
       "      <td>7200</td>\n",
       "      <td>Wind Advisory</td>\n",
       "      <td>WI</td>\n",
       "      <td>2018-12-29 15:54:00</td>\n",
       "      <td>2018-12-29 15:54:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420627</th>\n",
       "      <td>420628</td>\n",
       "      <td>PR</td>\n",
       "      <td>72</td>\n",
       "      <td>7200</td>\n",
       "      <td>Wind Advisory</td>\n",
       "      <td>WI</td>\n",
       "      <td>2018-12-30 00:26:00</td>\n",
       "      <td>2018-12-30 00:26:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420628</th>\n",
       "      <td>420629</td>\n",
       "      <td>PR</td>\n",
       "      <td>72</td>\n",
       "      <td>7200</td>\n",
       "      <td>Wind Advisory</td>\n",
       "      <td>WI</td>\n",
       "      <td>2018-12-30 00:40:00</td>\n",
       "      <td>2018-12-30 00:40:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1282 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0 state  STFIPS  districtId          event vtec  \\\n",
       "419347      419348    PR      72        7200  Coastal Flood   CF   \n",
       "419348      419349    PR      72        7200  Coastal Flood   CF   \n",
       "419349      419350    PR      72        7200  Coastal Flood   CF   \n",
       "419350      419351    PR      72        7200  Coastal Flood   CF   \n",
       "419351      419352    PR      72        7200  Coastal Flood   CF   \n",
       "...            ...   ...     ...         ...            ...  ...   \n",
       "420624      420625    PR      72        7200  Wind Advisory   WI   \n",
       "420625      420626    PR      72        7200  Wind Advisory   WI   \n",
       "420626      420627    PR      72        7200  Wind Advisory   WI   \n",
       "420627      420628    PR      72        7200  Wind Advisory   WI   \n",
       "420628      420629    PR      72        7200  Wind Advisory   WI   \n",
       "\n",
       "                  published              updated  \n",
       "419347  2019-01-23 23:56:00  2019-01-23 23:56:00  \n",
       "419348  2019-01-24 00:42:00  2019-01-24 00:42:00  \n",
       "419349  2019-01-24 05:21:00  2019-01-24 05:21:00  \n",
       "419350  2019-01-24 11:39:00  2019-01-24 11:39:00  \n",
       "419351  2019-08-27 18:54:00  2019-08-27 18:54:00  \n",
       "...                     ...                  ...  \n",
       "420624  2018-12-29 11:39:00  2018-12-29 11:39:00  \n",
       "420625  2018-12-29 13:35:00  2018-12-29 13:35:00  \n",
       "420626  2018-12-29 15:54:00  2018-12-29 15:54:00  \n",
       "420627  2018-12-30 00:26:00  2018-12-30 00:26:00  \n",
       "420628  2018-12-30 00:40:00  2018-12-30 00:40:00  \n",
       "\n",
       "[1282 rows x 8 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_df[event_df['state'] == 'PR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress_df.to_csv(\"./dataset/Congress_YCOM_2019_Data_abbr_region.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df_clean.to_csv(\"./dataset/districteventList_region_clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes:\n",
    "* It uses integers as *state_code*.\n",
    "* *state_label* is full names of states\n",
    "* there's no DC in the *state_label* while there is in the 2016 dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
